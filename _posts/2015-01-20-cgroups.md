---
layout: post
title: cgroups cpu相关笔记
---

## cpu硬限

cpu硬限，顾名思义，能够严格限制进程组的cpu使用率，cgroups通过如下两个file限制cpu硬限

		/cgroup/cpu/cpu.cfs_period_us
		/cgroup/cpu/cpu.cfs_quota_us

cfs 是完全公平调度器的缩写
cpu.cfs_period_us为时间周期，默认值为100000，即100ms
cpu.cfs_quota_us表示在时间周期里，可以使用的cpu时间，默认值为-1，表示不限制cpu使用时间

例如，想限制进程的cpu为1核，可以设置cpu.cfs_quota_us为100000
想限制cpu为4核，可以设置cpu.cfs_quota_us为400000

简单来说，cpu.cfs_quota_us和cpu.cfs_period_us的比值，就表示可以使用cpu的百分比

**这两个值在 cgroups 层次中是有限制的，下层的资源不能超过上层。具体的说，就是下层的 cpu.cfs_period_us 值不能小于上层的值，cpu.cfs_quota_us 值不能大于上层的值。**

## cpu软限

cpu软限，就是在cpu资源充足的情况下，可以超出cpu限制，充分利用cpu资源，如果cpu资源紧缺的条件下，按照一定的比例进行cpu资源分配，保证公平，cgroups通过如下file限制cpu软上限
		
		/cgroup/cpu/cpu.shares

cpu.shares 不是限制进程能使用的绝对的 cpu 时间，而是控制各个组之间的配额，例如：

		/cpu/cpu.shares : 1024
		/cpu/foo/cpu.shares : 2048
		
那么当两个组中的进程都满负荷运行时，/foo 中的进程所能占用的 cpu 就是 / 中的进程的两倍。如果再建一个 /foo/bar 的 cpu.shares 也是 1024，且也有满负荷运行的进程，那 /、/foo、/foo/bar 的 cpu 占用比就是 1:2:1 。前面说的是各自都跑满的情况。如果其他控制组中的进程闲着，那某一个组的进程完全可以用满全部 cpu。可见通常情况下，这种方式在保证公平的情况下能更充分利用资源。

## cpu绑定核心

cgroups中的cpuset子模块能实现cpu的核心和memory的绑定，限制进程组只能在使用固定的核心和内存节点，如下两个文件来限制

		/cgroup/cpuset/cpuset.cpus
		/cgroup/cpuset/cpuset.mems

两个参数中 cpu 核心、内存节点都用 id 表示，之间用 “,” 分隔。比如 0,1,2 。也可以用 “-” 表示范围，如 0-3 。两者可以结合起来用。如“0-2,6,7”。在添加进程前，cpuset.cpus、cpuset.mems 必须同时设置，而且必须是兼容的，否则会出错。

进程组的进程可以通过查看进程的状态查看绑定的核心

		cat /proc/<pid>/status|grep '_allowed_list'

## cpu资源统计

cgroups中的cpuacct子模块实现cpu资源统计，cpuacct.stat 统计了该控制组中进程用户态和内核态的 cpu 使用量，单位是 USER_HZ，也就是 jiffies、cpu 滴答数。每秒的滴答数可以用 getconf CLK_TCK 来获取，通常是 100。将看到的值除以这个值就可以换算成秒。

## 引用
[用 cgroups 管理 cpu 资源](http://xiezhenye.com/2013/10/用-cgroups-管理-cpu-资源.html)